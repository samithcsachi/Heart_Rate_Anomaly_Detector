{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffbfdd61",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd283915",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba9827ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a35fde99",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6a90442",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63aad981",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass(frozen=True)\n",
    "class ModelTrainerConfig:\n",
    "    root_dir: Path\n",
    "    train_heart_rate_data_path: Path\n",
    "    test_heart_rate_data_path: Path\n",
    "    train_is_anomaly_data_path: Path\n",
    "    test_is_anomaly_data_path: Path\n",
    "    data_transformation_dir: Path  \n",
    "    \n",
    "   \n",
    "    heart_rate_predictor_model_name: str\n",
    "    anomaly_detector_model_name: str\n",
    "    \n",
    "    \n",
    "    heart_rate_target_column: str\n",
    "    anomaly_target_column: str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "876ada10",
   "metadata": {},
   "outputs": [],
   "source": [
    "from Heart_Rate_Anomaly_Detector.constants import *\n",
    "from Heart_Rate_Anomaly_Detector.utils.common import read_yaml, create_directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4672ceb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConfigurationManager:\n",
    "    def __init__(\n",
    "        self,\n",
    "        config_filepath = CONFIG_FILE_PATH,\n",
    "        params_filepath = PARAMS_FILE_PATH,\n",
    "        schema_filepath = SCHEMA_FILE_PATH):\n",
    "\n",
    "        self.config = read_yaml(config_filepath)\n",
    "        self.params = read_yaml(params_filepath)\n",
    "        self.schema = read_yaml(schema_filepath)\n",
    "\n",
    "        create_directories([self.config.artifacts_root])\n",
    "        \n",
    "    def get_model_trainer_config(self) -> ModelTrainerConfig:\n",
    "        config = self.config.model_trainer\n",
    "        \n",
    "        \n",
    "        heart_rate_params = self.params.HEART_RATE_PREDICTOR\n",
    "        anomaly_params = self.params.ANOMALY_DETECTOR\n",
    "        \n",
    "       \n",
    "        heart_rate_model_schema = self.schema.models.HeartRatePredictor\n",
    "        anomaly_model_schema = self.schema.models.AnomalyDetector\n",
    "\n",
    "        create_directories([config.root_dir])\n",
    "\n",
    "        model_trainer_config = ModelTrainerConfig(\n",
    "            root_dir=Path(config.root_dir),\n",
    "            train_heart_rate_data_path=Path(config.data_path.train_heart_rate),\n",
    "            test_heart_rate_data_path=Path(config.data_path.test_heart_rate),\n",
    "            train_is_anomaly_data_path=Path(config.data_path.train_is_anomaly),\n",
    "            test_is_anomaly_data_path=Path(config.data_path.test_is_anomaly),\n",
    "            data_transformation_dir=Path(self.config.data_transformation.root_dir),\n",
    "            \n",
    "         \n",
    "            heart_rate_predictor_model_name=config.model_name.heart_rate_predictor,\n",
    "            anomaly_detector_model_name=config.model_name.anomaly_detector,\n",
    "            \n",
    "           \n",
    "            heart_rate_target_column=heart_rate_model_schema.target_column,\n",
    "            anomaly_target_column=anomaly_model_schema.target_column\n",
    "        )\n",
    "        return model_trainer_config\n",
    "    \n",
    "    def get_heart_rate_features(self) -> list:\n",
    "       \n",
    "        return self.schema.models.HeartRatePredictor.features\n",
    "    \n",
    "    def get_anomaly_features(self) -> list:\n",
    "       \n",
    "        return self.schema.models.AnomalyDetector.features\n",
    "    \n",
    "    def get_column_dtypes(self) -> dict:\n",
    "        \n",
    "        return self.schema.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46fc7d80",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import joblib\n",
    "from Heart_Rate_Anomaly_Detector import logger\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.metrics import accuracy_score, f1_score, r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a9553cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelTrainer:\n",
    "    def __init__(self, config, schema_config, params, model_name):\n",
    "        self.config = config\n",
    "        self.schema_config = schema_config\n",
    "        self.params = params\n",
    "        self.model_name = model_name\n",
    "        self.scaler = None\n",
    "        self.feature_columns = None\n",
    "\n",
    "        \n",
    "        self.target_column = schema_config.models[model_name].target_column\n",
    "        self.features = schema_config.models[model_name].features\n",
    "\n",
    "    def load_data(self):\n",
    "        \n",
    "        if self.model_name == \"HeartRatePredictor\":\n",
    "            train_data = pd.read_csv(self.config.train_heart_rate_data_path)\n",
    "            test_data = pd.read_csv(self.config.test_heart_rate_data_path)\n",
    "        elif self.model_name == \"AnomalyDetector\":\n",
    "            train_data = pd.read_csv(self.config.train_is_anomaly_data_path)\n",
    "            test_data = pd.read_csv(self.config.test_is_anomaly_data_path)\n",
    "        else:\n",
    "            raise ValueError(f\"Unknown model name: {self.model_name}\")\n",
    "        \n",
    "        logger.info(f\"Data loaded for {self.model_name}\")\n",
    "        return train_data, test_data\n",
    "\n",
    "    def prepare_features(self, train_data, test_data):\n",
    "        train_x = train_data[self.features].copy()\n",
    "        test_x = test_data[self.features].copy()\n",
    "\n",
    "        train_y = train_data[self.target_column]\n",
    "        test_y = test_data[self.target_column]\n",
    "\n",
    "       \n",
    "        cat_cols = train_x.select_dtypes(include=['object']).columns.tolist()\n",
    "        if cat_cols:\n",
    "            logger.info(f\"Encoding categorical columns: {cat_cols}\")\n",
    "            train_x = pd.get_dummies(train_x, columns=cat_cols, drop_first=True)\n",
    "            test_x = pd.get_dummies(test_x, columns=cat_cols, drop_first=True)\n",
    "            test_x = test_x.reindex(columns=train_x.columns, fill_value=0)\n",
    "\n",
    "        self.feature_columns = train_x.columns.tolist()\n",
    "        return train_x, test_x, train_y, test_y\n",
    "\n",
    "    def get_model(self):\n",
    "        if self.model_name == \"HeartRatePredictor\":\n",
    "            algo_config = self.params.HEART_RATE_PREDICTOR  \n",
    "            if algo_config.algorithm == \"random_forest\":     \n",
    "                return RandomForestRegressor(\n",
    "                    n_estimators=algo_config.n_estimators,   \n",
    "                    max_depth=algo_config.max_depth,         \n",
    "                    random_state=algo_config.random_state,   \n",
    "                    n_jobs=-1\n",
    "                )\n",
    "        elif self.model_name == \"AnomalyDetector\":\n",
    "            algo_config = self.params.ANOMALY_DETECTOR       \n",
    "            if algo_config.algorithm == \"isolation_forest\":  \n",
    "                return IsolationForest(\n",
    "                    contamination=algo_config.contamination,  \n",
    "                    n_estimators=algo_config.n_estimators,   \n",
    "                    random_state=algo_config.random_state     \n",
    "                )\n",
    "        raise ValueError(f\"Unsupported algorithm for {self.model_name}\")\n",
    "    \n",
    "\n",
    "    def save_model_artifacts(self, model, metrics=None, test_data=None):\n",
    "       \n",
    "        os.makedirs(self.config.root_dir, exist_ok=True)\n",
    "        \n",
    "        \n",
    "        model_artifacts = {\n",
    "            'model': model,\n",
    "            'scaler': self.scaler,\n",
    "            'feature_columns': self.feature_columns,\n",
    "            'target_column': self.target_column,\n",
    "            'model_type': type(model).__name__,\n",
    "            'timestamp': datetime.now().isoformat(),\n",
    "            'metrics': metrics\n",
    "        }\n",
    "        \n",
    "        model_path = os.path.join(self.config.root_dir, f\"{self.model_name}.joblib\")\n",
    "        joblib.dump(model_artifacts, model_path)\n",
    "        logger.info(f\"Model artifacts saved at: {model_path}\")\n",
    "\n",
    "      \n",
    "        if test_data is not None:\n",
    "            test_data_path = os.path.join(self.config.root_dir, f\"{self.model_name}_test_data.joblib\")\n",
    "            joblib.dump(test_data, test_data_path)\n",
    "            logger.info(f\"Test data saved at: {test_data_path}\")\n",
    "\n",
    "       \n",
    "        if hasattr(model, 'feature_importances_') and self.feature_columns:\n",
    "            feature_importance = pd.DataFrame({\n",
    "                'feature': self.feature_columns,\n",
    "                'importance': model.feature_importances_\n",
    "            }).sort_values('importance', ascending=False)\n",
    "            \n",
    "            importance_path = os.path.join(self.config.root_dir, f\"{self.model_name}_feature_importance.csv\")\n",
    "            feature_importance.to_csv(importance_path, index=False)\n",
    "            logger.info(f\"Feature importance saved at: {importance_path}\")\n",
    "\n",
    "           \n",
    "            logger.info(\"=== Top 10 Important Features ===\")\n",
    "            for idx, row in feature_importance.head(10).iterrows():\n",
    "                logger.info(f\"{row['feature']}: {row['importance']:.4f}\")\n",
    "\n",
    "\n",
    "    def train_model(self):\n",
    "        try:\n",
    "            train_data, test_data = self.load_data()\n",
    "            train_x, test_x, train_y, test_y = self.prepare_features(train_data, test_data)\n",
    "            model = self.get_model()\n",
    "            model.fit(train_x, train_y)\n",
    "\n",
    "            if self.model_name == \"HeartRatePredictor\":\n",
    "                train_preds = model.predict(train_x)\n",
    "                test_preds = model.predict(test_x)\n",
    "\n",
    "                train_rmse = np.sqrt(mean_squared_error(train_y, train_preds))\n",
    "                test_rmse = np.sqrt(mean_squared_error(test_y, test_preds))\n",
    "                test_r2 = r2_score(test_y, test_preds)\n",
    "\n",
    "                metrics = {\n",
    "                    \"train_rmse\": train_rmse,\n",
    "                    \"test_rmse\": test_rmse,\n",
    "                    \"test_r2\": test_r2\n",
    "                }\n",
    "                \n",
    "                print(\"=== Regression Results ===\")\n",
    "                print(f\"Train RMSE: {train_rmse:.4f}\")\n",
    "                print(f\"Test RMSE: {test_rmse:.4f}\")\n",
    "                print(f\"Test RÂ²: {test_r2:.4f}\")\n",
    "\n",
    "                test_data_to_save = pd.concat([test_x, test_y], axis=1)\n",
    "                self.save_model_artifacts(model, metrics=metrics, test_data=test_data_to_save)\n",
    "                logger.info(\"Model training for heart rate is completed successfully!\")\n",
    "\n",
    "            elif self.model_name == \"AnomalyDetector\":\n",
    "                train_preds = model.predict(train_x)\n",
    "                test_preds = model.predict(test_x)\n",
    "\n",
    "            \n",
    "                train_preds = (train_preds == -1).astype(int)\n",
    "                test_preds = (test_preds == -1).astype(int)\n",
    "\n",
    "                train_acc = accuracy_score(train_y, train_preds)\n",
    "                test_acc = accuracy_score(test_y, test_preds)\n",
    "                test_f1 = f1_score(test_y, test_preds)\n",
    "\n",
    "                metrics = {\n",
    "                    \"train_acc\": train_acc,\n",
    "                    \"test_acc\": test_acc,\n",
    "                    \"test_f1\": test_f1\n",
    "                }\n",
    "\n",
    "                print(\"=== Classification Results ===\")\n",
    "                print(f\"Train Accuracy: {train_acc:.4f}\")\n",
    "                print(f\"Test Accuracy: {test_acc:.4f}\")\n",
    "                print(f\"Test F1 Score: {test_f1:.4f}\")\n",
    "\n",
    "                test_data_to_save = pd.concat([test_x, test_y], axis=1)\n",
    "                self.save_model_artifacts(model, metrics=metrics, test_data=test_data_to_save)\n",
    "                logger.info(\"Model training for is anomaly completed successfully!\")\n",
    "\n",
    "            return model, test_preds\n",
    "        \n",
    "\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error in model training: {str(e)}\")\n",
    "            raise e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "694b2296",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    \n",
    "    config = ConfigurationManager()\n",
    "    model_trainer_config = config.get_model_trainer_config()\n",
    "    \n",
    "    hr_trainer = ModelTrainer(\n",
    "        config=model_trainer_config,\n",
    "        schema_config=schema,\n",
    "        params=params,\n",
    "        model_name=\"HeartRatePredictor\"\n",
    "    )\n",
    "    hr_model, hr_predictions = hr_trainer.train_model(train_hr_data, test_hr_data)\n",
    "    \n",
    "  \n",
    "    train_anomaly_data = pd.read_csv(model_trainer_config.train_is_anomaly_data_path)\n",
    "    test_anomaly_data = pd.read_csv(model_trainer_config.test_is_anomaly_data_path)\n",
    "    \n",
    "   \n",
    "   \n",
    "    anomaly_trainer = ModelTrainer(\n",
    "        config=model_trainer_config,\n",
    "        schema_config=schema,\n",
    "        params=params,\n",
    "        model_name=\"AnomalyDetector\"\n",
    "    )\n",
    "    anomaly_model, anomaly_predictions = anomaly_trainer.train_model(train_anomaly_data, test_anomaly_data)\n",
    "    \n",
    "  \n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Error occurred: {str(e)}\")\n",
    "    raise e"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
